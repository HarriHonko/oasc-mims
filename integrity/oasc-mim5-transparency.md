---
description: 'OASC MIM5: Fair and Transparent Artificial Intelligence'
---

# MIM5 - Transparency

## Status <a id="MIM1:ContextInformationManagement-Goal"></a>

<table>
  <thead>
    <tr>
      <th style="text-align:center">
        <p>&#x1F4A1;</p>
        <p>Work Item</p>
      </th>
      <th style="text-align:center">&gt;</th>
      <th style="text-align:center">
        <p>&#x1F9E9;</p>
        <p>Capabilities</p>
      </th>
      <th style="text-align:center">&gt;</th>
      <th style="text-align:center">
        <p>&#x1F3D7;</p>
        <p>Specification</p>
      </th>
      <th style="text-align:center">&gt;</th>
      <th style="text-align:center">
        <p>&#x1F469;&#x2696;</p>
        <p>Governance</p>
      </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align:center">&#x2705;</td>
      <td style="text-align:center"></td>
      <td style="text-align:center">&#x2705;</td>
      <td style="text-align:center"></td>
      <td style="text-align:center"></td>
      <td style="text-align:center"></td>
      <td style="text-align:center"></td>
    </tr>
  </tbody>
</table>

## Objectives

  
Governments, including local governments, are increasingly seeking to capture the opportunities offered by automated decision-making using algorithmic systems, to improve their services. However, government agencies and the general public have justified concerns over bias, privacy, accountability, and transparency of such automated decision-making processes. New examples continue to emerge of potential negative consequences from the inappropriate use of \(‘black box’\) algorithms. 

Here we define "Algorithmic System" as: "software that automatically makes predictions, makes decisions and/or gives advice by using data analysis, statistics and/or self-learning logic."

An automated decision-making algorithmic system does not necessarily require any form of self-learning logic \(such as machine learning\). In actual practice, software is often used that does not contain any self-learning logic, but the application of which may have great and sometimes unknown or unintended impact on citizens. 

To provide citizens and governments at all levels with a proper process to mitigate risk, Amsterdam city council, along with some other cities, proposed the Fair AI MIM 5 as part of their work to develop a European norm for procurement rules for government agencies to use when procuring algorithmic systems to support automated decision-making. Alongside this, guidance is being developed in different global regions regarding the actions that government agencies themselves need to take to assess the level of impact and to make sure that automated decision-making is trusted, fair and transparent. This will include providing channels for citizens to query the decision-making process and involving citizens in co-designing the algorithmic systems. Most importantly there is the need to ensure that the data used by those systems is accurate and appropriate e.g. through publicly available algorithmic registries.

The OASC MIM 5 will match these activities by focusing on the technical capabilities required to check that the algorithmic systems offered by the supplier comply with the requirements for fairness, trustworthiness and transparency.

## Capabilities

  
In order to match the procurement norm being developed, the following are the set of six minimal requirements for suppliers of algorithmic systems to ensure that these are fair, trustworthy and transparent.

**Procedural Transparency**

·       Full disclosure of the type of choices made, parties involved, risks and mitigation actions in the process of creating an algorithmic model.

**Technical Transparency**

·       full disclosure to allow the buyer of the source code and model to enable them to explain the model to citizens or other stakeholders.

·       Access to the learnings of the model, ideally structured using MIM2, to prevent vendor lock-ins.

·       Clarity about the process by which an algorithmic system makes decisions in an overall system, ie. the optimisation goals and outcomes of an algorithm.

**Technical Explainability**

·       Ability to explain on an individual level how a model creates certain outcomes.

·       Ability to address any restrictions as to whom the information will be classified: public servants, other experts, etc.

**Fairness**

·       Ensuring that the algorithmic systems does not systematically disadvantage, show bias against, or even discriminate against, different social groups and demographics.

**Context**

·       However, the assessment of fairness depends on facts, events, and goals, and therefore has to be understood as situation or task-specific and necessarily addressed within the scope of practice. For instance, there may be an explicit goal to address an historic imbalance, where positive discrimination is considered appropriate. Here the aspect of “fairness” needs to be seen in the wider context.

**Accountability**

·       Accountability for the supplier to create algorithms respecting human digital rights, and that is compliant with federal, state, and local anti-discrimination laws.

·       Agencies should not procure algorithms that are shielded from an independent validation and public review because of trade-secret or confidentiality claims.

It should be noted that these capabilities should be applied differently to different systems depending on the nature, context and goals of the algorithmic system.

Technically, these capabilities can be translated into a metadata API that every vendor would provide, when supplying high impact algorithms to cities, and the buyers could put in their requirements when procuring.



## Specifications <a id="MIM3:EcosystemTransactionManagement-Recommendedspecifications"></a>

Standard Clauses For Procurement Of Trustworthy Algorithmic Systems:  [https://www.amsterdam.nl/innovatie/digitalisering-technologie/contractual-terms-for-algorithms/](https://www.amsterdam.nl/innovatie/digitalisering-technologie/contractual-terms-for-algorithms/) 

White Paper on Public AI Registers: [https://algoritmeregister.amsterdam.nl/wp-content/uploads/White-Paper.pdf](https://algoritmeregister.amsterdam.nl/wp-content/uploads/White-Paper.pdf) 

Deliverables of the European Commission AI High-Level Expert Group \(AI HLEG\): [https://digital-strategy.ec.europa.eu/en/policies/expert-group-ai](https://digital-strategy.ec.europa.eu/en/policies/expert-group-ai) 

